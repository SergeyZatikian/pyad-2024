# -*- coding: utf-8 -*-


# Automatically generated by Colab.


import pandas as pd
import numpy as np
import pickle
from surprise import Dataset, Reader, SVD, accuracy, NormalPredictor
from surprise.model_selection import train_test_split as surprise_train_test_split
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import mean_absolute_error
from surprise.model_selection import cross_validate
from sklearn.linear_model import SGDRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error
from surprise.model_selection import GridSearchCV

"""–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–∞–±–ª–∏—Ü—É `Ratings`."""

ratings = pd.read_csv("Ratings.csv")
ratings.head()

ratings.info()
books = pd.read_csv("Books.csv")
books.head()



books.info()



books["Year-Of-Publication"].value_counts().sort_values(ascending=True)[:10]


books[books["Year-Of-Publication"].map(str).str.match("[^0-9]")]

books[(books["Book-Author"].isnull()) | (books["Publisher"].isnull())]




selected_rows = [209538, 220731, 221678]
selected_cols = books.columns[2:]


for idx in selected_rows:
    values = books.loc[idx, selected_cols].to_list()
    shifted_values = [values[-1]] + values[:-1]
    books.loc[idx, selected_cols] = shifted_values

books_filt = books.drop(columns=["Image-URL-S", "Image-URL-M", "Image-URL-L"])

books_filt["Year-Of-Publication"] = books_filt["Year-Of-Publication"].astype("int")


books_filt = books_filt[books_filt["Year-Of-Publication"] <= 2025].dropna()


ratings_df = ratings.copy()

ratings = ratings_df[ratings_df["Book-Rating"] != 0]

books_filt = books_filt[books_filt["ISBN"].isin(ratings["ISBN"])]

rating_counts = ratings["User-ID"].value_counts()


rating_not_one = rating_counts[rating_counts != 1].index
ratings = ratings[ratings["User-ID"].isin(rating_not_one)]

"""# –ü—Ä–∏—Å—Ç—É–ø–∞–µ–º –∫ –º–æ–¥–µ–ª—å–∫–∞–º üåü

–ü–µ—Ä–µ—å–µ—Ä–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è SVD
"""

algo = SVD()
reader = Reader(rating_scale=(1, 10))

data = Dataset.load_from_df(ratings[["User-ID", "ISBN", "Book-Rating"]], reader)
train_set = data.build_full_trainset()
param_grid = {"n_epochs": [15, 30], "lr_all": [0.002, 0.01], "reg_all": [0.4, 0.7]}
gs = GridSearchCV(SVD, param_grid, measures=["mae"], cv=3)


gs.fit(data)


print("–õ—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ MAE:", gs.best_score["mae"])
print("–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", gs.best_params["mae"])


svd_best = gs.best_estimator["mae"]
train_set = data.build_full_trainset()
svd_best.fit(train_set)

trains_set, test_set = surprise_train_test_split(data, test_size=0.3, random_state=313214)
predictions = svd_best.test(test_set)
mae_svd = accuracy.mae(predictions)
# —Å–æ—Ö—Ä–∞–Ω—è–µ–º
with open('svd.pkl', 'wb') as f:
    pickle.dump(svd_best, f)

merged_data = ratings.merge(books, on='ISBN')

vectorizer = TfidfVectorizer(max_features=100)
vectorized_titles = vectorizer.fit_transform(merged_data['Book-Title']).toarray()

categorical_features = merged_data[['Book-Author', 'Publisher', 'Year-Of-Publication']]
categorical_encoded = pd.DataFrame({
    col: pd.factorize(categorical_features[col])[0]
    for col in categorical_features.columns
})

features = pd.concat(
    [categorical_encoded.reset_index(drop=True), pd.DataFrame(vectorized_titles)],
    axis=1
)
features.columns = features.columns.astype(str)

y = merged_data['Book-Rating']

scaler = StandardScaler()
X = scaler.fit_transform(features)



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=29)


sgd = SGDRegressor()
sgd.fit(X_train, y_train)


y_pred = sgd.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")

with open('linreg.pkl', 'wb') as f:
    pickle.dump(sgd, f)

ratings.info()

"""–ù–∞—Ö–æ–¥–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

ratings_null =  ratings_df[ratings_df['Book-Rating'] == 0]
user = ratings_null[["User-ID", "Book-Rating"]].groupby("User-ID")["Book-Rating"].count().sort_values(ascending = False).reset_index().iloc[0,0]
book_user_null = ratings_df[ratings_df["User-ID"] == user]


reader = Reader(rating_scale=(1, 10))
data = Dataset.load_from_df(ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)
svd_model = load("svd_model.joblib")

recs = []
for i in book_user_null["ISBN"]:
  svd_pred = svd_best.predict(user, i).est
  if svd_pred >= 8:
        book_features = features[merged_data['ISBN'] == i].to_numpy()
        linreg_pred = sgd.predict(book_features)[0]
        recs.append((i, svd_pred, linreg_pred))


recs.sort(key=lambda x: x[2], reverse=True)

with open("user_recommendations.txt", "w") as rec_file:
    for isbn, svd_pred, linreg_pred in recs:

        book_title = books.loc[books['ISBN'] == isbn, 'Book-Title'].values[0]

        rec_file.write(
            f"Book: {book_title}\n"
            f"Predicted rating (SVD): {svd_pred:.2f}\n"
            f"Predicted rating (SGD): {linreg_pred:.2f}\n\n"
        )


